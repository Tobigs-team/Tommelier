{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCN_used_like_reduce_feature_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PFtCp4qmIavM"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFtCp4qmIavM"
      },
      "source": [
        "# DCN\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLwQzeStIhB0"
      },
      "source": [
        "# 1. Install & Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hldb2fdpTmCr",
        "outputId": "31733617-d18f-4a5e-93b7-30792f5db254"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk59gAgkHO1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7426e21-d423-4019-b716-9f38e0b2fadf"
      },
      "source": [
        "!pip install -q tensorflow-recommenders\r\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 51kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 4.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-ikzzWAGu2b"
      },
      "source": [
        "\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import pprint\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_recommenders as tfrs\r\n",
        "\r\n",
        "from tensorflow.keras.losses import binary_crossentropy\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping, Callback\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "import glob"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxVedkaONBo8"
      },
      "source": [
        "# 2. Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K2b8kxCNAEx"
      },
      "source": [
        "train = pd.read_json('/content/drive/MyDrive/tobigs14_conference/data/v_2/wine_meta/train_all_meta_v2.json')\r\n",
        "test = pd.read_json('/content/drive/MyDrive/tobigs14_conference/data/v_2/wine_meta/test_all_meta_v2.json')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ocyIGpNodJ"
      },
      "source": [
        "train = train.reset_index(drop=True)\r\n",
        "test = test.reset_index(drop=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dISQ8FbEzKAC"
      },
      "source": [
        "train.country_code= train.country_code.fillna('un')\r\n",
        "train.winery_id= train.winery_id.fillna('un')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9L0LLXC0KS0"
      },
      "source": [
        "train['grapes_id_unique'] = train.grapes_id.map(lambda x: x[0] if x else 0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIegKlHG0k7l"
      },
      "source": [
        "train = train[~train.food.isna()].reset_index(drop=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnfj8Qjd1RDm"
      },
      "source": [
        "train=train.drop(train[train['rank'].isna()].index)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyErVuIquycA"
      },
      "source": [
        "train=train[~train.type_id.isna()]\r\n",
        "train=train[~train.type_id.isna()]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuuMFYoRwgxk"
      },
      "source": [
        "train=train.drop(train[train['type_id']==25].index)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBgaP_wMrkTU"
      },
      "source": [
        "train = train[~train.body.isna()].reset_index(drop=True)\r\n",
        "train = train[~train.winery_id.isna()].reset_index(drop=True)\r\n",
        "train = train[~train.region_id.isna()].reset_index(drop=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GHFDaWIsecr"
      },
      "source": [
        "float 형태 데이터: rating_per_user, rating_average, winery_ratings_average, <br>\r\n",
        "grapes_id랑 같은 형태: country_most_used_grapes_wine_count, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOf_FGmjLXH4"
      },
      "source": [
        "INT_FEATURES = [\"type_id\", \"body\", \"acidity\", \"like\", 'user_like_count', 'rating_count', 'alcohol']\r\n",
        "\r\n",
        "for int_feature in INT_FEATURES:\r\n",
        "  train[int_feature] = train[int_feature].astype(int)\r\n",
        "\r\n",
        "train.country_code= train.country_code.fillna('un')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLpTU_nmLsat"
      },
      "source": [
        "train['grapes_id_unique'] = train.grapes_id.map(lambda x: x[0] if x else 0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E02Oo8HFN_Xw"
      },
      "source": [
        "# test data 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh9lSiyogZZP"
      },
      "source": [
        "test = test[~test.body.isna()].reset_index(drop=True)\r\n",
        "test = test[~test.winery_id.isna()].reset_index(drop=True)\r\n",
        "test = test[~test.region_id.isna()].reset_index(drop=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKsHmN5yRbRZ"
      },
      "source": [
        "INT_FEATURES = [\"type_id\", \"body\", \"acidity\", \"like\", 'user_like_count', 'rating_count', 'alcohol']\r\n",
        "\r\n",
        "\r\n",
        "for int_feature in INT_FEATURES:\r\n",
        "  test[int_feature] = test[int_feature].astype(int)\r\n",
        "\r\n",
        "test.country_code= test.country_code.fillna('un')\r\n",
        "test['grapes_id_unique'] = test.grapes_id.map(lambda x: x[0] if x else 0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QkwkEDw0L9c"
      },
      "source": [
        "- int: type_id, body, acidity, like, user_like_count, alcohol, grapes_id, winery_id\r\n",
        "- str: UserID, wine_id, country_code, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIsxP-eb-KsI"
      },
      "source": [
        "# dic type변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4D8Tb32gvhy"
      },
      "source": [
        "INT_FEATURES = [\"type_id\", \"body\", \"acidity\", \"like\", 'user_like_count', 'rating_count', 'alcohol']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXlPzSzKz78v"
      },
      "source": [
        "str_features = [\"userID\", \"country_code\", 'wine_id']\r\n",
        "int_features = [\"type_id\", \"body\", \"acidity\", \"like\", 'user_like_count', 'rating_count', 'alcohol', 'grapes_id_unique']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIHVsLDOz71D"
      },
      "source": [
        "train_str_dict = {\r\n",
        "    str_feature: [str(val).encode() for val in train[str_feature].values]\r\n",
        "    for str_feature in str_features\r\n",
        "}\r\n",
        "\r\n",
        "train_int_dict = {\r\n",
        "    int_feature: train[int_feature].values\r\n",
        "    for int_feature in int_features\r\n",
        "}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qohUJ8wv0kRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d31aae-b8b1-4cc5-bc33-77fa2f80a264"
      },
      "source": [
        "train_str_dict.update(train_int_dict)\r\n",
        "train_str_dict.keys()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['userID', 'country_code', 'wine_id', 'type_id', 'body', 'acidity', 'like', 'user_like_count', 'rating_count', 'alcohol', 'grapes_id_unique'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpDn3xnJz7rM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e670b41e-eada-443d-bd99-44548d68cc68"
      },
      "source": [
        "test_str_dict = {\r\n",
        "    str_feature: [str(val).encode() for val in test[str_feature].values]\r\n",
        "    for str_feature in str_features\r\n",
        "}\r\n",
        "\r\n",
        "test_int_dict = {\r\n",
        "    int_feature: test[int_feature].values\r\n",
        "    for int_feature in int_features\r\n",
        "}\r\n",
        "\r\n",
        "test_str_dict.update(test_int_dict)\r\n",
        "test_str_dict.keys()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['userID', 'country_code', 'wine_id', 'type_id', 'body', 'acidity', 'like', 'user_like_count', 'rating_count', 'alcohol', 'grapes_id_unique'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf-WuXKw0_fZ"
      },
      "source": [
        "train = tf.data.Dataset.from_tensor_slices(train_str_dict)\r\n",
        "test = tf.data.Dataset.from_tensor_slices(test_str_dict)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srUEH-U31XvP"
      },
      "source": [
        "# tf.keras.layers.experimental.preprocessing.\r\n",
        "feature_names = [\"userID\", \"country_code\", 'grapes_id_unique', \"type_id\", \"body\", \"acidity\", \"like\", 'user_like_count', 'rating_count', 'alcohol', 'wine_id']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M3RhFA81Joo"
      },
      "source": [
        "vocabularies = {}\r\n",
        "\r\n",
        "for feature_name in feature_names:\r\n",
        "  vocab = train.batch(1_000_000).map(lambda x: x[feature_name])\r\n",
        "  vocabularies[feature_name] = np.unique(np.concatenate(list(vocab)))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVarVb_wlwHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2866ebd5-e066-4982-ff4c-f090798e12a6"
      },
      "source": [
        "vocabularies"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acidity': array([1, 2, 3]),\n",
              " 'alcohol': array([  0,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
              "         15,  16,  17,  18,  19,  20,  21,  80, 112, 114, 135]),\n",
              " 'body': array([1, 2, 3, 4, 5]),\n",
              " 'country_code': array([b'ar', b'at', b'au', b'br', b'ca', b'ch', b'cl', b'de', b'es',\n",
              "        b'fr', b'gb', b'gr', b'hu', b'il', b'it', b'jp', b'lu', b'mx',\n",
              "        b'nz', b'pt', b'ru', b'us', b'uy', b'za'], dtype=object),\n",
              " 'grapes_id_unique': array([   0,    1,    2,    3,    5,    6,    7,    8,    9,   10,   11,\n",
              "          12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,\n",
              "          23,   24,   25,   29,   31,   32,   33,   34,   35,   36,   37,\n",
              "          38,   39,   40,   41,   42,   43,   44,   45,   46,   47,   48,\n",
              "          49,   50,   51,   52,   53,   54,   55,   56,   57,   58,   59,\n",
              "          62,   63,   64,   67,   68,   69,   70,   71,   74,   75,   76,\n",
              "          77,   78,   80,   81,   82,   83,   85,   86,   88,   89,   91,\n",
              "          92,   93,   94,   96,   97,   98,  100,  101,  102,  103,  104,\n",
              "         105,  106,  108,  109,  110,  111,  112,  114,  115,  116,  118,\n",
              "         119,  120,  122,  123,  124,  127,  128,  129,  130,  131,  132,\n",
              "         135,  136,  137,  138,  142,  144,  145,  147,  148,  149,  150,\n",
              "         151,  156,  157,  158,  159,  161,  162,  165,  166,  167,  168,\n",
              "         169,  170,  171,  172,  173,  174,  175,  176,  177,  178,  179,\n",
              "         180,  184,  190,  191,  192,  196,  197,  198,  199,  200,  202,\n",
              "         204,  206,  209,  210,  215,  216,  219,  221,  222,  224,  225,\n",
              "         226,  228,  231,  232,  233,  235,  239,  241,  242,  243,  245,\n",
              "         246,  251,  252,  254,  255,  257,  259,  260,  261,  262,  264,\n",
              "         265,  267,  268,  270,  271,  273,  274,  275,  280,  282,  283,\n",
              "         284,  286,  289,  291,  292,  293,  294,  295,  299,  300,  302,\n",
              "         304,  308,  309,  310,  311,  312,  314,  316,  317,  318,  320,\n",
              "         321,  325,  334,  335,  336,  337,  339,  341,  343,  348,  349,\n",
              "         353,  354,  355,  363,  365,  366,  367,  368,  370,  374,  377,\n",
              "         382,  383,  385,  386,  387,  388,  389,  390,  454,  464,  474,\n",
              "         504,  514,  524,  534,  545,  546,  547,  548,  550,  553,  557,\n",
              "         562,  565,  566,  567,  572,  573,  576,  577,  579,  580,  583,\n",
              "         584,  585,  586,  589,  594,  597,  601,  608,  614,  617,  628,\n",
              "         630,  633,  634,  635,  642,  643,  653,  661,  662,  664,  669,\n",
              "         671,  673,  674,  675,  677,  678,  698,  702,  714,  725,  732,\n",
              "         750,  760,  780,  785,  839,  847,  852,  883,  887,  927,  938,\n",
              "         947,  951,  957,  966,  973,  975,  978, 1005, 1006, 1011, 1019,\n",
              "        1030, 1032, 1033, 1034, 1044, 1072, 1074, 1098, 1116, 1121, 1156,\n",
              "        1175, 1176, 1178, 1185, 1222, 1232, 1262, 1265, 1266, 1281, 1282,\n",
              "        1285, 1291, 1320, 1333, 1336, 1353, 1364, 1374, 1394, 1427, 1495,\n",
              "        1519, 1529, 1536, 1543, 1544, 1551, 1555, 1587, 1589, 1594, 1595,\n",
              "        1596, 1602, 1632, 1639, 1645, 1665, 1670, 1672, 1675, 1677, 1678,\n",
              "        1680, 1687, 1688, 1697, 1710, 1715, 1716, 1718, 1719, 1721, 1730,\n",
              "        1733, 1739]),\n",
              " 'like': array([0, 1]),\n",
              " 'rating_count': array([    10,     11,     12, ..., 122634, 123375, 148911]),\n",
              " 'type_id': array([ 1,  2,  3,  4,  7, 24]),\n",
              " 'userID': array([b'10001895', b'10003665', b'10006310', ..., b'9990646', b'9993784',\n",
              "        b'9993829'], dtype=object),\n",
              " 'user_like_count': array([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
              "          11,   12,   13,   14,   15,   16,   17,   18,   19,   20,   21,\n",
              "          22,   23,   24,   25,   26,   27,   28,   29,   30,   31,   32,\n",
              "          33,   34,   35,   36,   37,   38,   39,   40,   41,   42,   43,\n",
              "          44,   45,   46,   47,   48,   49,   50,   51,   52,   53,   54,\n",
              "          55,   56,   57,   58,   59,   60,   61,   62,   63,   64,   65,\n",
              "          66,   67,   68,   69,   70,   71,   72,   73,   74,   75,   76,\n",
              "          77,   78,   79,   80,   81,   82,   83,   84,   85,   86,   87,\n",
              "          88,   89,   90,   91,   92,   93,   94,   95,   96,   97,   98,\n",
              "          99,  100,  101,  102,  103,  104,  105,  106,  107,  108,  109,\n",
              "         110,  111,  112,  113,  114,  115,  116,  117,  118,  119,  120,\n",
              "         121,  122,  123,  124,  125,  126,  127,  128,  129,  130,  131,\n",
              "         132,  133,  134,  135,  136,  137,  138,  139,  140,  141,  142,\n",
              "         143,  144,  145,  146,  147,  148,  149,  150,  151,  152,  153,\n",
              "         154,  155,  156,  157,  158,  159,  160,  161,  162,  163,  164,\n",
              "         165,  166,  167,  168,  169,  170,  171,  172,  173,  174,  175,\n",
              "         176,  177,  178,  179,  180,  181,  182,  183,  184,  185,  186,\n",
              "         187,  188,  189,  190,  191,  192,  193,  194,  195,  196,  197,\n",
              "         198,  199,  200,  201,  202,  203,  204,  205,  206,  207,  208,\n",
              "         209,  210,  211,  212,  213,  214,  215,  216,  217,  218,  219,\n",
              "         220,  221,  222,  223,  224,  225,  226,  227,  228,  229,  230,\n",
              "         231,  232,  233,  234,  235,  236,  237,  238,  239,  240,  241,\n",
              "         242,  243,  244,  245,  246,  247,  248,  249,  250,  251,  252,\n",
              "         253,  254,  255,  256,  257,  258,  259,  260,  261,  262,  263,\n",
              "         264,  265,  266,  267,  268,  269,  270,  271,  272,  273,  274,\n",
              "         275,  276,  277,  278,  279,  280,  281,  282,  283,  284,  285,\n",
              "         286,  287,  288,  289,  290,  291,  292,  293,  294,  295,  296,\n",
              "         297,  298,  299,  300,  301,  302,  303,  304,  305,  306,  307,\n",
              "         309,  310,  311,  312,  313,  314,  315,  316,  317,  318,  319,\n",
              "         320,  321,  322,  323,  324,  325,  326,  327,  328,  329,  330,\n",
              "         332,  333,  334,  335,  336,  338,  339,  340,  341,  342,  343,\n",
              "         345,  346,  347,  348,  350,  351,  352,  353,  354,  355,  356,\n",
              "         357,  358,  359,  360,  362,  365,  366,  367,  368,  369,  370,\n",
              "         371,  372,  373,  375,  378,  379,  382,  384,  386,  388,  389,\n",
              "         390,  391,  395,  396,  397,  399,  400,  402,  404,  405,  406,\n",
              "         407,  408,  409,  411,  412,  416,  417,  418,  419,  421,  424,\n",
              "         425,  427,  428,  429,  430,  432,  434,  436,  444,  445,  451,\n",
              "         453,  458,  459,  466,  470,  475,  476,  477,  480,  481,  489,\n",
              "         491,  496,  500,  502,  504,  513,  514,  520,  528,  531,  532,\n",
              "         537,  539,  540,  547,  562,  565,  572,  573,  577,  578,  580,\n",
              "         583,  587,  601,  607,  611,  640,  643,  671,  699,  720,  755,\n",
              "        1111]),\n",
              " 'wine_id': array([b'10000', b'100002', b'100006', ..., b'99984', b'99986', b'99988'],\n",
              "       dtype=object)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bnUjk4E16hw"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsVJomi_157c"
      },
      "source": [
        "class DCN(tfrs.Model):\r\n",
        "\r\n",
        "  def __init__(self, use_cross_layer, deep_layer_sizes, projection_dim=None):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.embedding_dimension = 32\r\n",
        "\r\n",
        "    str_features = [\"userID\", \"country_code\", 'wine_id']\r\n",
        "    int_features = [\"type_id\", \"body\", \"acidity\", 'user_like_count', 'rating_count', 'alcohol', 'grapes_id_unique']\r\n",
        "\r\n",
        "    self._all_features = str_features + int_features\r\n",
        "    self._embeddings = {}\r\n",
        "\r\n",
        "    # Compute embeddings for string features.\r\n",
        "    for feature_name in str_features:\r\n",
        "      vocabulary = vocabularies[feature_name]\r\n",
        "      self._embeddings[feature_name] = tf.keras.Sequential(\r\n",
        "          [tf.keras.layers.experimental.preprocessing.StringLookup(\r\n",
        "              vocabulary=vocabulary, mask_token=None),\r\n",
        "           tf.keras.layers.Embedding(len(vocabulary) + 1,\r\n",
        "                                     self.embedding_dimension)\r\n",
        "    ])\r\n",
        "      \r\n",
        "    # Compute embeddings for int features.\r\n",
        "    for feature_name in int_features:\r\n",
        "      vocabulary = vocabularies[feature_name]\r\n",
        "      self._embeddings[feature_name] = tf.keras.Sequential(\r\n",
        "          [tf.keras.layers.experimental.preprocessing.IntegerLookup(\r\n",
        "              vocabulary=vocabulary, mask_value=None),\r\n",
        "           tf.keras.layers.Embedding(len(vocabulary) + 1,\r\n",
        "                                     self.embedding_dimension)\r\n",
        "    ])\r\n",
        "\r\n",
        "    if use_cross_layer:\r\n",
        "      self._cross_layer = tfrs.layers.dcn.Cross(\r\n",
        "          projection_dim=projection_dim,\r\n",
        "          kernel_initializer=\"glorot_uniform\")\r\n",
        "    else:\r\n",
        "      self._cross_layer = None\r\n",
        "\r\n",
        "    self._deep_layers = [tf.keras.layers.Dense(layer_size, activation=\"relu\")\r\n",
        "      for layer_size in deep_layer_sizes]\r\n",
        "\r\n",
        "    self._logit_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\r\n",
        "\r\n",
        "    self.task = tfrs.tasks.Ranking(\r\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(),\r\n",
        "      metrics=[tf.keras.metrics.BinaryCrossentropy(\"binary_accuracy\")]\r\n",
        "    )\r\n",
        "\r\n",
        "  def call(self, features):\r\n",
        "    # Concatenate embeddings\r\n",
        "    embeddings = []\r\n",
        "    for feature_name in self._all_features:\r\n",
        "      embedding_fn = self._embeddings[feature_name]\r\n",
        "      embeddings.append(embedding_fn(features[feature_name]))\r\n",
        "\r\n",
        "    x = tf.concat(embeddings, axis=1)\r\n",
        "\r\n",
        "    # Build Cross Network\r\n",
        "    if self._cross_layer is not None:\r\n",
        "      x = self._cross_layer(x)\r\n",
        "    \r\n",
        "    # Build Deep Network\r\n",
        "    for deep_layer in self._deep_layers:\r\n",
        "      x = deep_layer(x)\r\n",
        "\r\n",
        "    return self._logit_layer(x)\r\n",
        "\r\n",
        "  def compute_loss(self, features, training=False):\r\n",
        "    labels = features.pop(\"like\")\r\n",
        "    scores = self(features)\r\n",
        "    return self.task(\r\n",
        "        labels=labels,\r\n",
        "        predictions=scores,\r\n",
        "    )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEv7OXOJ15zI"
      },
      "source": [
        "learning_rate = 0.001"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZpkjqpY15oJ"
      },
      "source": [
        "cached_train = train.shuffle(100_000).batch(8192).cache()\r\n",
        "cached_test = test.batch(5989).cache()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajCIZkwt2B3v"
      },
      "source": [
        "model = DCN(use_cross_layer=True, deep_layer_sizes=[192, 192], projection_dim=None)\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo1nxyl42EoP"
      },
      "source": [
        "# Train & Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJyPk7tP2Bxt"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "\r\n",
        "cached_test_numpy = tfds.as_numpy(cached_test)\r\n",
        "y_true = [item['like'] for item in cached_test_numpy]\r\n",
        "y_true = np.concatenate(y_true)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY7sAuVV2BpC"
      },
      "source": [
        "def get_result(model):\r\n",
        "  y_pred = model.predict(cached_test).flatten()\r\n",
        "  y_pred_class = [1 if pred > 0.5 else 0 for pred in y_pred]\r\n",
        "\r\n",
        "  print(f\"ROC: {roc_auc_score(y_true, y_pred)}\")\r\n",
        "  print(classification_report(y_true, y_pred_class))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6UxUXOIlhib"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\r\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='binary_accuracy', patience=20)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqOuIBngzEDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d446512-9862-4b47-dedc-799aee19768b"
      },
      "source": [
        "history= model.fit(cached_train,  epochs=500, verbose=True, callbacks=[callback])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "87/87 [==============================] - 11s 108ms/step - binary_accuracy: 0.6361 - loss: 0.6352 - regularization_loss: 0.0000e+00 - total_loss: 0.6352\n",
            "Epoch 2/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.5438 - loss: 0.5423 - regularization_loss: 0.0000e+00 - total_loss: 0.5423\n",
            "Epoch 3/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.5174 - loss: 0.5155 - regularization_loss: 0.0000e+00 - total_loss: 0.5155\n",
            "Epoch 4/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.5058 - loss: 0.5036 - regularization_loss: 0.0000e+00 - total_loss: 0.5036\n",
            "Epoch 5/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.4978 - loss: 0.4958 - regularization_loss: 0.0000e+00 - total_loss: 0.4958\n",
            "Epoch 6/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.4938 - loss: 0.4918 - regularization_loss: 0.0000e+00 - total_loss: 0.4918\n",
            "Epoch 7/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.4866 - loss: 0.4844 - regularization_loss: 0.0000e+00 - total_loss: 0.4844\n",
            "Epoch 8/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.4767 - loss: 0.4742 - regularization_loss: 0.0000e+00 - total_loss: 0.4742\n",
            "Epoch 9/500\n",
            "87/87 [==============================] - 2s 22ms/step - binary_accuracy: 0.4641 - loss: 0.4615 - regularization_loss: 0.0000e+00 - total_loss: 0.4615\n",
            "Epoch 10/500\n",
            "87/87 [==============================] - 2s 22ms/step - binary_accuracy: 0.4498 - loss: 0.4471 - regularization_loss: 0.0000e+00 - total_loss: 0.4471\n",
            "Epoch 11/500\n",
            "87/87 [==============================] - 2s 22ms/step - binary_accuracy: 0.4324 - loss: 0.4296 - regularization_loss: 0.0000e+00 - total_loss: 0.4296\n",
            "Epoch 12/500\n",
            "87/87 [==============================] - 2s 22ms/step - binary_accuracy: 0.4128 - loss: 0.4100 - regularization_loss: 0.0000e+00 - total_loss: 0.4100\n",
            "Epoch 13/500\n",
            "87/87 [==============================] - 2s 22ms/step - binary_accuracy: 0.3920 - loss: 0.3893 - regularization_loss: 0.0000e+00 - total_loss: 0.3893\n",
            "Epoch 14/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.3710 - loss: 0.3683 - regularization_loss: 0.0000e+00 - total_loss: 0.3683\n",
            "Epoch 15/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.3502 - loss: 0.3475 - regularization_loss: 0.0000e+00 - total_loss: 0.3475\n",
            "Epoch 16/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.3319 - loss: 0.3292 - regularization_loss: 0.0000e+00 - total_loss: 0.3292\n",
            "Epoch 17/500\n",
            "87/87 [==============================] - 2s 22ms/step - binary_accuracy: 0.3230 - loss: 0.3204 - regularization_loss: 0.0000e+00 - total_loss: 0.3204\n",
            "Epoch 18/500\n",
            "87/87 [==============================] - 2s 22ms/step - binary_accuracy: 0.3149 - loss: 0.3123 - regularization_loss: 0.0000e+00 - total_loss: 0.3123\n",
            "Epoch 19/500\n",
            "87/87 [==============================] - 2s 22ms/step - binary_accuracy: 0.2950 - loss: 0.2923 - regularization_loss: 0.0000e+00 - total_loss: 0.2923\n",
            "Epoch 20/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.2710 - loss: 0.2684 - regularization_loss: 0.0000e+00 - total_loss: 0.2684\n",
            "Epoch 21/500\n",
            "87/87 [==============================] - 2s 21ms/step - binary_accuracy: 0.2478 - loss: 0.2454 - regularization_loss: 0.0000e+00 - total_loss: 0.2454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1fodt2q0fli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be181a9-c57f-4cb1-e086-ac9a1a47d015"
      },
      "source": [
        "get_result(model)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC: 0.9223335284801448\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84     80975\n",
            "           1       0.85      0.88      0.86     93390\n",
            "\n",
            "    accuracy                           0.85    174365\n",
            "   macro avg       0.85      0.85      0.85    174365\n",
            "weighted avg       0.85      0.85      0.85    174365\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZmF-jNm35d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9349e58d-2bda-4814-afcd-dcfe35b31504"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"dcn_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_15 (Sequential)   (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "sequential_18 (Sequential)   (None, 32)                800       \n",
            "_________________________________________________________________\n",
            "sequential_14 (Sequential)   (None, 32)                192       \n",
            "_________________________________________________________________\n",
            "sequential_11 (Sequential)   (None, 32)                800       \n",
            "_________________________________________________________________\n",
            "sequential_19 (Sequential)   (None, 32)                12768     \n",
            "_________________________________________________________________\n",
            "sequential_17 (Sequential)   (None, 32)                247584    \n",
            "_________________________________________________________________\n",
            "sequential_13 (Sequential)   (None, 32)                224       \n",
            "_________________________________________________________________\n",
            "sequential_10 (Sequential)   (None, 32)                203008    \n",
            "_________________________________________________________________\n",
            "sequential_16 (Sequential)   (None, 32)                14496     \n",
            "_________________________________________________________________\n",
            "sequential_12 (Sequential)   (None, 32)                1415104   \n",
            "_________________________________________________________________\n",
            "cross_1 (Cross)              multiple                  102720    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  61632     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  37056     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  193       \n",
            "_________________________________________________________________\n",
            "ranking_1 (Ranking)          multiple                  2         \n",
            "=================================================================\n",
            "Total params: 2,096,707\n",
            "Trainable params: 2,096,705\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSVxjNOb53N3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "cef24120-d675-4302-88a0-c33a315bbbc3"
      },
      "source": [
        "mat = model._cross_layer._dense.kernel\r\n",
        "features = model._all_features\r\n",
        "\r\n",
        "block_norm = np.ones([len(features), len(features)])\r\n",
        "\r\n",
        "dim = model.embedding_dimension\r\n",
        "\r\n",
        "# Compute the norms of the blocks.\r\n",
        "for i in range(len(features)):\r\n",
        "  for j in range(len(features)):\r\n",
        "    block = mat[i * dim:(i + 1) * dim,\r\n",
        "                j * dim:(j + 1) * dim]\r\n",
        "    block_norm[i,j] = np.linalg.norm(block, ord=\"fro\")\r\n",
        "\r\n",
        "plt.figure(figsize=(100,100))\r\n",
        "im = plt.matshow(block_norm, cmap=plt.cm.Blues)\r\n",
        "ax = plt.gca()\r\n",
        "divider = make_axes_locatable(plt.gca())\r\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\r\n",
        "plt.colorbar(im, cax=cax)\r\n",
        "cax.tick_params(labelsize=10) \r\n",
        "_ = ax.set_xticklabels([\"\"] + features, rotation=45, ha=\"left\", fontsize=10)\r\n",
        "_ = ax.set_yticklabels([\"\"] + features, fontsize=10)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 7200x7200 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}