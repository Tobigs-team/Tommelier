{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBTOhQ463t7z",
    "outputId": "34db595c-d49e-45dc-eab9-40214b3d7466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/á„‚á…©á†«á„†á…®á†«/DCN\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/á„‚á…©á†«á„†á…®á†«/DCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2usum1jB5bHe",
    "outputId": "139493f8-8bb6-46d4-b144-837ae10e35e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220_dcn.ipynb           train_v2_201130.json  Wine_Meta_final_201229.csv\n",
      "1227_DCN_practive.ipynb  user_test_v2.json     Wine_segment_201229.csv\n",
      "test_v2_201130.json      user_train_v2.json\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65nKvxZD5e9j",
    "outputId": "589c28fa-eee5-45fc-85e5-257ac49de1af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 8.1MB/s \n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.6MB 13.2MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "id": "4Fwep3Dx5njv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import glob\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping, Callback\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "3Q_K49pf5vvR"
   },
   "source": [
    "# 0. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "id": "ASm4pmAi5qr4"
   },
   "outputs": [],
   "source": [
    "# 0. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "id": "NIYEMAos5uhg"
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('train_v2_201130.json')\n",
    "test = pd.read_json('test_v2_201130.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "saoP8nR752wc",
    "outputId": "d932bad5-7deb-41bd-aba2-0b0eb1bfd9e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_note</th>\n",
       "      <th>rating_per_user</th>\n",
       "      <th>vintage_id</th>\n",
       "      <th>user_like_count</th>\n",
       "      <th>userID</th>\n",
       "      <th>wine_id</th>\n",
       "      <th>wine_name</th>\n",
       "      <th>url</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Soooo good ðŸ’•</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164942680</td>\n",
       "      <td>0</td>\n",
       "      <td>19484511</td>\n",
       "      <td>1141133</td>\n",
       "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
       "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BelÃ­ssimo champanhe rose, bem seco mais com mu...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164942680</td>\n",
       "      <td>2</td>\n",
       "      <td>352674</td>\n",
       "      <td>1141133</td>\n",
       "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
       "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>164942680</td>\n",
       "      <td>0</td>\n",
       "      <td>17786617</td>\n",
       "      <td>1141133</td>\n",
       "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
       "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfekt med gratinerede Ã¸sters.</td>\n",
       "      <td>4.5</td>\n",
       "      <td>164942680</td>\n",
       "      <td>0</td>\n",
       "      <td>8078038</td>\n",
       "      <td>1141133</td>\n",
       "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
       "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Delicious!</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164942680</td>\n",
       "      <td>0</td>\n",
       "      <td>3014532</td>\n",
       "      <td>1141133</td>\n",
       "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
       "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  ... like\n",
       "0      0  ...    1\n",
       "1      1  ...    1\n",
       "2      4  ...    1\n",
       "3      5  ...    1\n",
       "4      6  ...    0\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MF4Yup4jD08j",
    "outputId": "dd9d062f-ad4d-4af4-8189-91c45e1d0210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((763387, 10), (188718, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "id": "p9fTbUA0Db6R"
   },
   "outputs": [],
   "source": [
    "item = pd.read_csv('Wine_segment_201229.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "C4_NozHvD7Qe",
    "outputId": "a5894fed-74e5-4414-8fc6-0d32fe3ce13a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine_id</th>\n",
       "      <th>name</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>rating_average</th>\n",
       "      <th>label_count</th>\n",
       "      <th>review_count</th>\n",
       "      <th>body</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>winery_ratings_count</th>\n",
       "      <th>winery_ratings_average</th>\n",
       "      <th>winery_labels_count</th>\n",
       "      <th>winery_wines_count</th>\n",
       "      <th>Aperitif</th>\n",
       "      <th>Appetizers and snacks</th>\n",
       "      <th>Blue cheese</th>\n",
       "      <th>Cured Meat</th>\n",
       "      <th>Fruity desserts</th>\n",
       "      <th>Game</th>\n",
       "      <th>Goat cheese</th>\n",
       "      <th>Lamb</th>\n",
       "      <th>Lean fish</th>\n",
       "      <th>Mature and hard cheese</th>\n",
       "      <th>Mild and soft cheese</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Pasta</th>\n",
       "      <th>Pork</th>\n",
       "      <th>Poultry</th>\n",
       "      <th>Rich fish</th>\n",
       "      <th>Shellfish</th>\n",
       "      <th>Spicy food</th>\n",
       "      <th>Sweet desserts</th>\n",
       "      <th>Veal</th>\n",
       "      <th>Vegetarian</th>\n",
       "      <th>Beef</th>\n",
       "      <th>Blue cheese.1</th>\n",
       "      <th>Fruity desserts.1</th>\n",
       "      <th>Game .1</th>\n",
       "      <th>Lamb.1</th>\n",
       "      <th>Mature and hard cheese.1</th>\n",
       "      <th>Pasta.1</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_18</th>\n",
       "      <th>pca_19</th>\n",
       "      <th>pca_20</th>\n",
       "      <th>pca_21</th>\n",
       "      <th>pca_22</th>\n",
       "      <th>pca_23</th>\n",
       "      <th>pca_24</th>\n",
       "      <th>pca_25</th>\n",
       "      <th>pca_26</th>\n",
       "      <th>pca_27</th>\n",
       "      <th>pca_28</th>\n",
       "      <th>pca_29</th>\n",
       "      <th>pca_30</th>\n",
       "      <th>pca_31</th>\n",
       "      <th>pca_32</th>\n",
       "      <th>pca_33</th>\n",
       "      <th>pca_34</th>\n",
       "      <th>pca_35</th>\n",
       "      <th>pca_36</th>\n",
       "      <th>pca_37</th>\n",
       "      <th>pca_38</th>\n",
       "      <th>pca_39</th>\n",
       "      <th>pca_40</th>\n",
       "      <th>pca_41</th>\n",
       "      <th>pca_42</th>\n",
       "      <th>pca_43</th>\n",
       "      <th>pca_44</th>\n",
       "      <th>pca_45</th>\n",
       "      <th>pca_46</th>\n",
       "      <th>pca_47</th>\n",
       "      <th>pca_48</th>\n",
       "      <th>pca_49</th>\n",
       "      <th>pca_50</th>\n",
       "      <th>pca_51</th>\n",
       "      <th>grapes_id</th>\n",
       "      <th>region_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>type_id</th>\n",
       "      <th>winery_id</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1938520</td>\n",
       "      <td>1882 Cabernet Sauvignon</td>\n",
       "      <td>1697</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14879</td>\n",
       "      <td>16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>18888.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>121618.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.551669</td>\n",
       "      <td>4.234245</td>\n",
       "      <td>-4.399549</td>\n",
       "      <td>-1.394831</td>\n",
       "      <td>4.230004</td>\n",
       "      <td>2.214657</td>\n",
       "      <td>3.698479</td>\n",
       "      <td>-11.544035</td>\n",
       "      <td>3.926973</td>\n",
       "      <td>2.027013</td>\n",
       "      <td>-3.108813</td>\n",
       "      <td>0.066079</td>\n",
       "      <td>3.901737</td>\n",
       "      <td>5.336387</td>\n",
       "      <td>-2.893791</td>\n",
       "      <td>-7.887779</td>\n",
       "      <td>-12.434086</td>\n",
       "      <td>5.029867</td>\n",
       "      <td>-2.870348</td>\n",
       "      <td>1.098466</td>\n",
       "      <td>0.041303</td>\n",
       "      <td>-0.516198</td>\n",
       "      <td>0.322788</td>\n",
       "      <td>-0.443685</td>\n",
       "      <td>-3.136951</td>\n",
       "      <td>0.742006</td>\n",
       "      <td>0.173241</td>\n",
       "      <td>-1.924884</td>\n",
       "      <td>-1.610956</td>\n",
       "      <td>2.868221</td>\n",
       "      <td>-2.167123</td>\n",
       "      <td>1.151749</td>\n",
       "      <td>1.444787</td>\n",
       "      <td>2.489641</td>\n",
       "      <td>[2]</td>\n",
       "      <td>105.0</td>\n",
       "      <td>us</td>\n",
       "      <td>1</td>\n",
       "      <td>2412.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14604</td>\n",
       "      <td>Les Bessards Hermitage</td>\n",
       "      <td>1078</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5370</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>72079.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>462021.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.201073</td>\n",
       "      <td>3.788378</td>\n",
       "      <td>1.210495</td>\n",
       "      <td>1.083187</td>\n",
       "      <td>0.590964</td>\n",
       "      <td>3.617076</td>\n",
       "      <td>0.106284</td>\n",
       "      <td>7.155894</td>\n",
       "      <td>1.924063</td>\n",
       "      <td>-1.217552</td>\n",
       "      <td>3.798950</td>\n",
       "      <td>-0.573204</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>2.294474</td>\n",
       "      <td>-1.256222</td>\n",
       "      <td>-1.491831</td>\n",
       "      <td>-2.579453</td>\n",
       "      <td>-0.628009</td>\n",
       "      <td>-0.097134</td>\n",
       "      <td>-4.154698</td>\n",
       "      <td>-2.861205</td>\n",
       "      <td>-4.497887</td>\n",
       "      <td>1.583489</td>\n",
       "      <td>-0.026252</td>\n",
       "      <td>-1.082327</td>\n",
       "      <td>0.338037</td>\n",
       "      <td>-2.199833</td>\n",
       "      <td>-0.638129</td>\n",
       "      <td>1.981586</td>\n",
       "      <td>1.148229</td>\n",
       "      <td>-0.780446</td>\n",
       "      <td>-1.026985</td>\n",
       "      <td>-3.631833</td>\n",
       "      <td>-0.124608</td>\n",
       "      <td>[1]</td>\n",
       "      <td>535.0</td>\n",
       "      <td>fr</td>\n",
       "      <td>1</td>\n",
       "      <td>7636.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1930757</td>\n",
       "      <td>Patriarch Estate Grown</td>\n",
       "      <td>1072</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6042</td>\n",
       "      <td>25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>7747.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>49362.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.994470</td>\n",
       "      <td>3.356056</td>\n",
       "      <td>-0.923651</td>\n",
       "      <td>0.741282</td>\n",
       "      <td>2.596084</td>\n",
       "      <td>7.155602</td>\n",
       "      <td>-1.910814</td>\n",
       "      <td>-3.998637</td>\n",
       "      <td>-0.054258</td>\n",
       "      <td>0.587277</td>\n",
       "      <td>-0.887633</td>\n",
       "      <td>-0.478954</td>\n",
       "      <td>-0.442926</td>\n",
       "      <td>-1.749812</td>\n",
       "      <td>-1.185678</td>\n",
       "      <td>-0.141588</td>\n",
       "      <td>0.728802</td>\n",
       "      <td>-1.242658</td>\n",
       "      <td>0.493817</td>\n",
       "      <td>-1.872077</td>\n",
       "      <td>-2.067729</td>\n",
       "      <td>-3.043356</td>\n",
       "      <td>0.165190</td>\n",
       "      <td>0.615640</td>\n",
       "      <td>-0.657080</td>\n",
       "      <td>0.566004</td>\n",
       "      <td>0.658332</td>\n",
       "      <td>-0.343338</td>\n",
       "      <td>-1.285816</td>\n",
       "      <td>0.543290</td>\n",
       "      <td>-0.569400</td>\n",
       "      <td>1.647680</td>\n",
       "      <td>-1.445715</td>\n",
       "      <td>-0.359417</td>\n",
       "      <td>[2, 10]</td>\n",
       "      <td>88.0</td>\n",
       "      <td>us</td>\n",
       "      <td>1</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1564280</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>3577</td>\n",
       "      <td>4.3</td>\n",
       "      <td>18748</td>\n",
       "      <td>52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>14091.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>83324.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.055126</td>\n",
       "      <td>-6.163670</td>\n",
       "      <td>-17.412258</td>\n",
       "      <td>3.399827</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>17.899010</td>\n",
       "      <td>-2.046424</td>\n",
       "      <td>-11.186761</td>\n",
       "      <td>12.007775</td>\n",
       "      <td>0.894301</td>\n",
       "      <td>5.050331</td>\n",
       "      <td>-2.478301</td>\n",
       "      <td>8.826864</td>\n",
       "      <td>7.167604</td>\n",
       "      <td>-6.359656</td>\n",
       "      <td>-1.473321</td>\n",
       "      <td>-3.462038</td>\n",
       "      <td>4.614712</td>\n",
       "      <td>-0.875028</td>\n",
       "      <td>-7.256990</td>\n",
       "      <td>-2.221329</td>\n",
       "      <td>-6.283630</td>\n",
       "      <td>-0.477432</td>\n",
       "      <td>0.779232</td>\n",
       "      <td>2.592272</td>\n",
       "      <td>-0.271975</td>\n",
       "      <td>1.884531</td>\n",
       "      <td>0.176404</td>\n",
       "      <td>4.579372</td>\n",
       "      <td>1.793655</td>\n",
       "      <td>-4.051642</td>\n",
       "      <td>3.926317</td>\n",
       "      <td>-2.261881</td>\n",
       "      <td>-0.431446</td>\n",
       "      <td>[10]</td>\n",
       "      <td>24.0</td>\n",
       "      <td>us</td>\n",
       "      <td>1</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2576427</td>\n",
       "      <td>Cabernet Sauvignon F Block</td>\n",
       "      <td>115</td>\n",
       "      <td>4.4</td>\n",
       "      <td>806</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7749.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>-0.478264</td>\n",
       "      <td>-1.010209</td>\n",
       "      <td>-0.003157</td>\n",
       "      <td>0.367176</td>\n",
       "      <td>-0.270334</td>\n",
       "      <td>-0.550214</td>\n",
       "      <td>0.490301</td>\n",
       "      <td>-0.315579</td>\n",
       "      <td>0.299809</td>\n",
       "      <td>-0.471115</td>\n",
       "      <td>-0.199453</td>\n",
       "      <td>-0.326484</td>\n",
       "      <td>-0.776345</td>\n",
       "      <td>-0.717146</td>\n",
       "      <td>0.147173</td>\n",
       "      <td>0.347295</td>\n",
       "      <td>-0.071307</td>\n",
       "      <td>0.385532</td>\n",
       "      <td>-0.230784</td>\n",
       "      <td>0.216109</td>\n",
       "      <td>0.222512</td>\n",
       "      <td>-0.104980</td>\n",
       "      <td>-0.133218</td>\n",
       "      <td>-0.016644</td>\n",
       "      <td>-0.063100</td>\n",
       "      <td>-0.098678</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>0.164888</td>\n",
       "      <td>-0.078193</td>\n",
       "      <td>0.113466</td>\n",
       "      <td>0.270745</td>\n",
       "      <td>0.158934</td>\n",
       "      <td>-0.330067</td>\n",
       "      <td>[2]</td>\n",
       "      <td>42.0</td>\n",
       "      <td>us</td>\n",
       "      <td>1</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wine_id                        name  ...  winery_id  segment\n",
       "0  1938520     1882 Cabernet Sauvignon  ...     2412.0        2\n",
       "1    14604      Les Bessards Hermitage  ...     7636.0        2\n",
       "2  1930757      Patriarch Estate Grown  ...     1905.0        2\n",
       "3  1564280                      Merlot  ...     1297.0        2\n",
       "4  2576427  Cabernet Sauvignon F Block  ...     2232.0        2\n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "3JjrbiN5uZ2S"
   },
   "source": [
    "# 1. Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false",
    "id": "kXe-6WSvuPso"
   },
   "outputs": [],
   "source": [
    "train = train[['userID', 'wine_id', 'like']]\n",
    "test = test[['userID', 'wine_id', 'like']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "SO8ZFdsGvUMr",
    "outputId": "577586aa-56ba-4866-ec4e-6b47646b8064"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine_id</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>rating_average</th>\n",
       "      <th>review_count</th>\n",
       "      <th>body</th>\n",
       "      <th>acidity_y</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type_id</th>\n",
       "      <th>grapes_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>region_id</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1938520</td>\n",
       "      <td>1697</td>\n",
       "      <td>4.1</td>\n",
       "      <td>16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.485010</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>us</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14604</td>\n",
       "      <td>1078</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.429150</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>fr</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1930757</td>\n",
       "      <td>1072</td>\n",
       "      <td>4.6</td>\n",
       "      <td>25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.851015</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "      <td>[2, 10]</td>\n",
       "      <td>us</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1564280</td>\n",
       "      <td>3577</td>\n",
       "      <td>4.3</td>\n",
       "      <td>52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.775668</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1</td>\n",
       "      <td>[10]</td>\n",
       "      <td>us</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2576427</td>\n",
       "      <td>115</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.511364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>us</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50855</th>\n",
       "      <td>1669561</td>\n",
       "      <td>788</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.212859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[104, 34]</td>\n",
       "      <td>it</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50856</th>\n",
       "      <td>1861275</td>\n",
       "      <td>231</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.072673</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[5]</td>\n",
       "      <td>it</td>\n",
       "      <td>613.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50857</th>\n",
       "      <td>2201892</td>\n",
       "      <td>390</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.982507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[112]</td>\n",
       "      <td>it</td>\n",
       "      <td>3232.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50858</th>\n",
       "      <td>2396179</td>\n",
       "      <td>302</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.061171</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[17]</td>\n",
       "      <td>fr</td>\n",
       "      <td>635.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50859</th>\n",
       "      <td>7715684</td>\n",
       "      <td>82</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.560714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[88]</td>\n",
       "      <td>es</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50860 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wine_id  rating_count  rating_average  ...  country_code  region_id  segment\n",
       "0      1938520          1697             4.1  ...            us      105.0        2\n",
       "1        14604          1078             4.3  ...            fr      535.0        2\n",
       "2      1930757          1072             4.6  ...            us       88.0        2\n",
       "3      1564280          3577             4.3  ...            us       24.0        2\n",
       "4      2576427           115             4.4  ...            us       42.0        2\n",
       "...        ...           ...             ...  ...           ...        ...      ...\n",
       "50855  1669561           788             3.5  ...            it      983.0        1\n",
       "50856  1861275           231             3.8  ...            it      613.0        1\n",
       "50857  2201892           390             3.9  ...            it     3232.0        1\n",
       "50858  2396179           302             4.2  ...            fr      635.0        3\n",
       "50859  7715684            82             4.1  ...            es     1687.0        2\n",
       "\n",
       "[50860 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_item = item[[\n",
    "      'wine_id',\n",
    "      'rating_count',\n",
    "      'rating_average',\n",
    "      'review_count',\n",
    "      'body',\n",
    "      'acidity_y',\n",
    "      'alcohol',\n",
    "      'type_id',\n",
    "      'grapes_id',\n",
    "      'country_code',\n",
    "      'region_id',\n",
    "      'segment'\n",
    "]]\n",
    "\n",
    "selected_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false",
    "id": "QnnQu07OGSV_"
   },
   "outputs": [],
   "source": [
    "train.loc[train['wine_id'] == 1886805, 'wine_id'] = 1183966\n",
    "test.loc[test['wine_id'] == 1886805, 'wine_id'] = 1183966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "ROxPukdYutjk",
    "outputId": "2b64174d-4dce-4146-c092-11b014e553bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>wine_id</th>\n",
       "      <th>like</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>rating_average</th>\n",
       "      <th>review_count</th>\n",
       "      <th>body</th>\n",
       "      <th>acidity_y</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type_id</th>\n",
       "      <th>grapes_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>region_id</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19484511</td>\n",
       "      <td>1141133</td>\n",
       "      <td>1</td>\n",
       "      <td>5248</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.283229</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 14, 110]</td>\n",
       "      <td>fr</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352674</td>\n",
       "      <td>1141133</td>\n",
       "      <td>1</td>\n",
       "      <td>5248</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.283229</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 14, 110]</td>\n",
       "      <td>fr</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17786617</td>\n",
       "      <td>1141133</td>\n",
       "      <td>1</td>\n",
       "      <td>5248</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.283229</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 14, 110]</td>\n",
       "      <td>fr</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8078038</td>\n",
       "      <td>1141133</td>\n",
       "      <td>1</td>\n",
       "      <td>5248</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.283229</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 14, 110]</td>\n",
       "      <td>fr</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3014532</td>\n",
       "      <td>1141133</td>\n",
       "      <td>0</td>\n",
       "      <td>5248</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.283229</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 14, 110]</td>\n",
       "      <td>fr</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763382</th>\n",
       "      <td>11274168</td>\n",
       "      <td>87064</td>\n",
       "      <td>0</td>\n",
       "      <td>1379</td>\n",
       "      <td>3.8</td>\n",
       "      <td>37</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.045876</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[49]</td>\n",
       "      <td>es</td>\n",
       "      <td>766.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763383</th>\n",
       "      <td>11274168</td>\n",
       "      <td>63654</td>\n",
       "      <td>1</td>\n",
       "      <td>9222</td>\n",
       "      <td>3.9</td>\n",
       "      <td>178</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.339126</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[7]</td>\n",
       "      <td>fr</td>\n",
       "      <td>387.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763384</th>\n",
       "      <td>11274168</td>\n",
       "      <td>5602</td>\n",
       "      <td>1</td>\n",
       "      <td>23457</td>\n",
       "      <td>4.4</td>\n",
       "      <td>865</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.695950</td>\n",
       "      <td>14.4</td>\n",
       "      <td>2</td>\n",
       "      <td>[5]</td>\n",
       "      <td>us</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763385</th>\n",
       "      <td>11274168</td>\n",
       "      <td>1396664</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.493441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>us</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763386</th>\n",
       "      <td>11274168</td>\n",
       "      <td>1142712</td>\n",
       "      <td>0</td>\n",
       "      <td>21638</td>\n",
       "      <td>3.9</td>\n",
       "      <td>262</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.891555</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>us</td>\n",
       "      <td>327.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>763387 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userID  wine_id  like  ...  country_code  region_id  segment\n",
       "0       19484511  1141133     1  ...            fr      409.0        3\n",
       "1         352674  1141133     1  ...            fr      409.0        3\n",
       "2       17786617  1141133     1  ...            fr      409.0        3\n",
       "3        8078038  1141133     1  ...            fr      409.0        3\n",
       "4        3014532  1141133     0  ...            fr      409.0        3\n",
       "...          ...      ...   ...  ...           ...        ...      ...\n",
       "763382  11274168    87064     0  ...            es      766.0        1\n",
       "763383  11274168    63654     1  ...            fr      387.0        3\n",
       "763384  11274168     5602     1  ...            us       96.0        3\n",
       "763385  11274168  1396664     0  ...            us       25.0        2\n",
       "763386  11274168  1142712     0  ...            us      327.0        2\n",
       "\n",
       "[763387 rows x 14 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_train = train.merge(selected_item, on = 'wine_id', how = 'left')\n",
    "add_test = test.merge(selected_item, on = 'wine_id', how = 'left')\n",
    "\n",
    "add_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPruvbalv3d-",
    "outputId": "9ba2e845-7b47-4436-af90-87cc94eb9c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 763387 entries, 0 to 763386\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   userID          763387 non-null  int64  \n",
      " 1   wine_id         763387 non-null  int64  \n",
      " 2   like            763387 non-null  int64  \n",
      " 3   rating_count    763387 non-null  int64  \n",
      " 4   rating_average  763387 non-null  float64\n",
      " 5   review_count    763387 non-null  int64  \n",
      " 6   body            763387 non-null  float64\n",
      " 7   acidity_y       763387 non-null  float64\n",
      " 8   alcohol         763387 non-null  float64\n",
      " 9   type_id         763387 non-null  int64  \n",
      " 10  grapes_id       763387 non-null  object \n",
      " 11  country_code    763387 non-null  object \n",
      " 12  region_id       763387 non-null  float64\n",
      " 13  segment         763387 non-null  int64  \n",
      "dtypes: float64(5), int64(7), object(2)\n",
      "memory usage: 87.4+ MB\n"
     ]
    }
   ],
   "source": [
    "add_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B77nxCbawHLW",
    "outputId": "f7431af1-bed0-43a7-c703-041b277b1213"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID            0\n",
       "wine_id           0\n",
       "like              0\n",
       "rating_count      0\n",
       "rating_average    0\n",
       "review_count      0\n",
       "body              0\n",
       "acidity_y         0\n",
       "alcohol           0\n",
       "type_id           0\n",
       "grapes_id         0\n",
       "country_code      0\n",
       "region_id         0\n",
       "segment           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "DekllzMl0aPQ",
    "outputId": "64016977-1f9c-48a6-94dc-af7e5c5c95fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>wine_id</th>\n",
       "      <th>like</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>rating_average</th>\n",
       "      <th>review_count</th>\n",
       "      <th>body</th>\n",
       "      <th>acidity_y</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type_id</th>\n",
       "      <th>grapes_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>region_id</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19484511</td>\n",
       "      <td>1141133</td>\n",
       "      <td>1</td>\n",
       "      <td>5248</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.283229</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 14, 110]</td>\n",
       "      <td>fr</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352674</td>\n",
       "      <td>1141133</td>\n",
       "      <td>1</td>\n",
       "      <td>5248</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.283229</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 14, 110]</td>\n",
       "      <td>fr</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17786617</td>\n",
       "      <td>1141133</td>\n",
       "      <td>1</td>\n",
       "      <td>5248</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.283229</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 14, 110]</td>\n",
       "      <td>fr</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8078038</td>\n",
       "      <td>1141133</td>\n",
       "      <td>1</td>\n",
       "      <td>5248</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.283229</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 14, 110]</td>\n",
       "      <td>fr</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3014532</td>\n",
       "      <td>1141133</td>\n",
       "      <td>0</td>\n",
       "      <td>5248</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.283229</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 14, 110]</td>\n",
       "      <td>fr</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID  wine_id  like  ...  country_code  region_id  segment\n",
       "0  19484511  1141133     1  ...            fr      409.0        3\n",
       "1    352674  1141133     1  ...            fr      409.0        3\n",
       "2  17786617  1141133     1  ...            fr      409.0        3\n",
       "3   8078038  1141133     1  ...            fr      409.0        3\n",
       "4   3014532  1141133     0  ...            fr      409.0        3\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "id": "nykMm5NpMObm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "yfNyvKFlIqXQ"
   },
   "source": [
    "# 2. Data Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "Collapsed": "false",
    "id": "0-s4mY6oGpme"
   },
   "outputs": [],
   "source": [
    "str_features = ['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code', 'region_id', 'segment']\n",
    "int_features = ['rating_count', 'rating_average', 'review_count', 'body', 'acidity_y', 'alcohol', 'like']\n",
    "feature_names = str_features + int_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZPn8OhZSZw2",
    "outputId": "13bafdf1-2509-488c-a19d-7a35479b6e49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code',\n",
       "       'region_id', 'segment', 'rating_count', 'rating_average',\n",
       "       'review_count', 'body', 'acidity_y', 'alcohol', 'like'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "Collapsed": "false",
    "id": "enVTATM3M0xf"
   },
   "outputs": [],
   "source": [
    "def setType(df):\n",
    "\n",
    "  df['rating_average'] = df['rating_average'].apply(lambda x : x * 10)\n",
    "  df['acidity_y'] = df['acidity_y'].apply(lambda x : x * 10)\n",
    "  df['grapes_id'] = df['grapes_id'].apply(lambda x : x[0])\n",
    "\n",
    "  for f in int_features:\n",
    "    df[f] = df[f].astype(int)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "Collapsed": "false",
    "id": "GZ5Yl7LuK5Gk"
   },
   "outputs": [],
   "source": [
    "add_train = setType(add_train)\n",
    "add_test = setType(add_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZikrncL_HcCt",
    "outputId": "8e7c848c-0b6e-4f2e-dd44-a8a10d9c7cbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code', 'region_id', 'segment', 'rating_count', 'rating_average', 'review_count', 'body', 'acidity_y', 'alcohol', 'like'])"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_str_dict = {\n",
    "    str_feature: [str(val).encode() for val in add_train[str_feature].values]\n",
    "    for str_feature in str_features\n",
    "}\n",
    "\n",
    "train_int_dict = {\n",
    "    int_feature: add_train[int_feature].values\n",
    "    for int_feature in int_features\n",
    "}\n",
    "\n",
    "train_str_dict.update(train_int_dict)\n",
    "train_str_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kp7pSrLbHeNs",
    "outputId": "4c494dfe-5f87-4525-8012-d3465c0e52f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code', 'region_id', 'segment', 'rating_count', 'rating_average', 'review_count', 'body', 'acidity_y', 'alcohol', 'like'])"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str_dict = {\n",
    "    str_feature: [str(val).encode() for val in add_test[str_feature].values]\n",
    "    for str_feature in str_features\n",
    "}\n",
    "\n",
    "test_int_dict = {\n",
    "    int_feature: add_test[int_feature].values\n",
    "    for int_feature in int_features\n",
    "}\n",
    "\n",
    "test_str_dict.update(test_int_dict)\n",
    "test_str_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "Collapsed": "false",
    "id": "4D_oUDERH5fA"
   },
   "outputs": [],
   "source": [
    "tensor_train = tf.data.Dataset.from_tensor_slices(train_str_dict)\n",
    "tensor_test = tf.data.Dataset.from_tensor_slices(test_str_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqU-0VChH-dZ",
    "outputId": "0a7a19f2-039a-49f2-f6e8-10f34ba84649"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:12<00:00,  5.20s/it]\n"
     ]
    }
   ],
   "source": [
    "vocabularies = {}\n",
    "\n",
    "for feature_name in tqdm(feature_names):\n",
    "  vocab = tensor_train.batch(1_000_000).map(lambda x: x[feature_name])\n",
    "  vocabularies[feature_name] = np.unique(np.concatenate(list(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-4BLWkMIM4P",
    "outputId": "bba74e45-200c-4f8f-e8bf-eda8af625aee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acidity_y': array([ 0,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
       "        26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
       "        43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
       "        60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75]),\n",
       " 'alcohol': array([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  23,  45,  80, 112, 114,\n",
       "        135]),\n",
       " 'body': array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " 'country_code': array([b'al', b'am', b'ar', b'at', b'au', b'be', b'bg', b'bo', b'br',\n",
       "        b'ca', b'ch', b'cl', b'cn', b'cy', b'cz', b'de', b'dk', b'es',\n",
       "        b'fr', b'gb', b'ge', b'gr', b'hr', b'hu', b'il', b'in', b'it',\n",
       "        b'jp', b'lb', b'lu', b'ma', b'md', b'me', b'mk', b'mt', b'mx',\n",
       "        b'nl', b'nz', b'pe', b'ps', b'pt', b'ro', b'rs', b'ru', b'se',\n",
       "        b'si', b'sk', b'th', b'tn', b'tr', b'ua', b'unk', b'us', b'uy',\n",
       "        b'za'], dtype=object),\n",
       " 'grapes_id': array([b'0', b'['], dtype=object),\n",
       " 'like': array([0, 1]),\n",
       " 'rating_average': array([ 0, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
       "        40, 41, 42, 43, 44, 45, 46, 47, 48]),\n",
       " 'rating_count': array([     4,      6,      9, ..., 122634, 123375, 148911]),\n",
       " 'region_id': array([b'0.0', b'100.0', b'1034.0', ..., b'99.0', b'992.0', b'996.0'],\n",
       "       dtype=object),\n",
       " 'review_count': array([    0,     1,     2, ..., 16540, 21005, 22865]),\n",
       " 'segment': array([b'0', b'1', b'2', b'3'], dtype=object),\n",
       " 'type_id': array([b'1', b'2', b'24', b'25', b'3', b'4', b'7'], dtype=object),\n",
       " 'userID': array([b'10001895', b'10003665', b'10006310', ..., b'9990646', b'9993784',\n",
       "        b'9993829'], dtype=object),\n",
       " 'wine_id': array([b'10', b'10000', b'100002', ..., b'99984', b'99986', b'99988'],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabularies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "pn1j7dRrIyEe"
   },
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "Collapsed": "false",
    "id": "GrXu9OzwInWT"
   },
   "outputs": [],
   "source": [
    "class DCN(tfrs.Model):\n",
    "\n",
    "  def __init__(self, use_cross_layer, deep_layer_sizes, projection_dim=None):\n",
    "    super().__init__()\n",
    "\n",
    "    self.embedding_dimension = 32\n",
    "\n",
    "    str_features = ['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code', 'region_id', 'segment']\n",
    "    int_features = ['rating_count', 'rating_average', 'review_count', 'body', 'acidity_y', 'alcohol']\n",
    "    # feature_names = str_features + int_features\n",
    "\n",
    "    self._all_features = str_features + int_features\n",
    "    self._embeddings = {}\n",
    "\n",
    "    # Compute embeddings for string features.\n",
    "    for feature_name in str_features:\n",
    "      vocabulary = vocabularies[feature_name]\n",
    "      self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "          [tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=vocabulary, mask_token=None),\n",
    "           tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                     self.embedding_dimension)\n",
    "    ])\n",
    "      \n",
    "    # Compute embeddings for int features.\n",
    "    for feature_name in int_features:\n",
    "      vocabulary = vocabularies[feature_name]\n",
    "      self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "          [tf.keras.layers.experimental.preprocessing.IntegerLookup(\n",
    "              vocabulary=vocabulary, mask_value=None),\n",
    "           tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                     self.embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    if use_cross_layer:\n",
    "      self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "          projection_dim=projection_dim,\n",
    "          kernel_initializer=\"glorot_uniform\")\n",
    "    else:\n",
    "      self._cross_layer = None\n",
    "\n",
    "    self._deep_layers = [tf.keras.layers.Dense(layer_size, activation=\"relu\")\n",
    "      for layer_size in deep_layer_sizes]\n",
    "\n",
    "    self._logit_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "\n",
    "    self.task = tfrs.tasks.Ranking(\n",
    "      # loss=tf.keras.losses.MeanSquaredError(),\n",
    "      loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=[\n",
    "              #  tf.keras.metrics.RootMeanSquaredError(\"RMSE\")\n",
    "              tf.keras.metrics.BinaryAccuracy(\n",
    "                  name='binary_accuracy', dtype=None, threshold=0.5\n",
    "                  )\n",
    "               ]\n",
    "    )\n",
    "\n",
    "  def call(self, features):\n",
    "    # Concatenate embeddings\n",
    "    embeddings = []\n",
    "    for feature_name in self._all_features:\n",
    "      embedding_fn = self._embeddings[feature_name]\n",
    "      embeddings.append(embedding_fn(features[feature_name]))\n",
    "\n",
    "    x = tf.concat(embeddings, axis=1)\n",
    "\n",
    "    # Build Cross Network\n",
    "    if self._cross_layer is not None:\n",
    "      x = self._cross_layer(x)\n",
    "    \n",
    "    # Build Deep Network\n",
    "    for deep_layer in self._deep_layers:\n",
    "      x = deep_layer(x)\n",
    "\n",
    "    return self._logit_layer(x)\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    labels = features.pop(\"like\")\n",
    "    scores = self(features)\n",
    "    return self.task(\n",
    "        labels=labels,\n",
    "        predictions=scores,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "Collapsed": "false",
    "id": "VrcazKx4JNB5"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "cached_train = tensor_train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = tensor_test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "Collapsed": "false",
    "id": "uikNZ3VyJSis"
   },
   "outputs": [],
   "source": [
    "model = DCN(use_cross_layer = True, deep_layer_sizes = [192, 192], projection_dim = None)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "XAdCJ3j6Jdpf"
   },
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fonQwNY7JbAw",
    "outputId": "461c90a6-f7b1-4f23-b1a6-fe54fd293059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 16s 150ms/step - binary_accuracy: 0.6666 - loss: 0.6068 - regularization_loss: 0.0000e+00 - total_loss: 0.6068\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.7333 - loss: 0.5322 - regularization_loss: 0.0000e+00 - total_loss: 0.5322\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7485 - loss: 0.5081 - regularization_loss: 0.0000e+00 - total_loss: 0.5081\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7594 - loss: 0.4893 - regularization_loss: 0.0000e+00 - total_loss: 0.4893\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7650 - loss: 0.4784 - regularization_loss: 0.0000e+00 - total_loss: 0.4784\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7708 - loss: 0.4663 - regularization_loss: 0.0000e+00 - total_loss: 0.4663\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7677 - loss: 0.4669 - regularization_loss: 0.0000e+00 - total_loss: 0.4669\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7687 - loss: 0.4623 - regularization_loss: 0.0000e+00 - total_loss: 0.4623\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7751 - loss: 0.4488 - regularization_loss: 0.0000e+00 - total_loss: 0.4488\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.7780 - loss: 0.4396 - regularization_loss: 0.0000e+00 - total_loss: 0.4396\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(cached_train,  epochs = 10, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "Collapsed": "false",
    "id": "X3CT807rJlVJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "cached_test_numpy = tfds.as_numpy(cached_test)\n",
    "y_true = [item['like'] for item in cached_test_numpy]\n",
    "y_true = np.concatenate(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "Collapsed": "false",
    "id": "iakFdv6YQU72"
   },
   "outputs": [],
   "source": [
    "def get_result(model):\n",
    "  y_pred = model.predict(cached_test).flatten()\n",
    "  y_pred_class = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "  print(f\"ROC: {roc_auc_score(y_true, y_pred)}\")\n",
    "  print(classification_report(y_true, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBQAehcfQ6yC",
    "outputId": "99caf825-6827-4828-f897-456f2f994c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC: 0.8192714723026125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71     88227\n",
      "           1       0.75      0.76      0.75    100491\n",
      "\n",
      "    accuracy                           0.74    188718\n",
      "   macro avg       0.73      0.73      0.73    188718\n",
      "weighted avg       0.74      0.74      0.74    188718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_result(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "Collapsed": "false",
    "id": "s1fBus_2VWwA"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "callbacks_list = [\n",
    "                  keras.callbacks.EarlyStopping(\n",
    "                    monitor = 'binary_accuracy',\n",
    "                    patience = 15\n",
    "                  )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3L_YebbQ92b",
    "outputId": "4c970702-42c9-4750-c69f-89bb96fc2118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.7860 - loss: 0.4268 - regularization_loss: 0.0000e+00 - total_loss: 0.4268\n",
      "Epoch 2/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.7805 - loss: 0.4305 - regularization_loss: 0.0000e+00 - total_loss: 0.4305\n",
      "Epoch 3/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7886 - loss: 0.4193 - regularization_loss: 0.0000e+00 - total_loss: 0.4193\n",
      "Epoch 4/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7920 - loss: 0.4104 - regularization_loss: 0.0000e+00 - total_loss: 0.4104\n",
      "Epoch 5/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7880 - loss: 0.4145 - regularization_loss: 0.0000e+00 - total_loss: 0.4145\n",
      "Epoch 6/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7772 - loss: 0.4280 - regularization_loss: 0.0000e+00 - total_loss: 0.4280\n",
      "Epoch 7/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.7930 - loss: 0.4047 - regularization_loss: 0.0000e+00 - total_loss: 0.4047\n",
      "Epoch 8/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.7781 - loss: 0.4222 - regularization_loss: 0.0000e+00 - total_loss: 0.4222\n",
      "Epoch 9/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.7828 - loss: 0.4127 - regularization_loss: 0.0000e+00 - total_loss: 0.4127\n",
      "Epoch 10/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.7895 - loss: 0.3979 - regularization_loss: 0.0000e+00 - total_loss: 0.3979\n",
      "Epoch 11/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.8002 - loss: 0.3786 - regularization_loss: 0.0000e+00 - total_loss: 0.3786\n",
      "Epoch 12/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.8109 - loss: 0.3590 - regularization_loss: 0.0000e+00 - total_loss: 0.3590\n",
      "Epoch 13/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.8211 - loss: 0.3382 - regularization_loss: 0.0000e+00 - total_loss: 0.3382\n",
      "Epoch 14/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.8309 - loss: 0.3185 - regularization_loss: 0.0000e+00 - total_loss: 0.3185\n",
      "Epoch 15/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.8393 - loss: 0.3038 - regularization_loss: 0.0000e+00 - total_loss: 0.3038\n",
      "Epoch 16/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.8487 - loss: 0.2852 - regularization_loss: 0.0000e+00 - total_loss: 0.2852\n",
      "Epoch 17/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.8601 - loss: 0.2604 - regularization_loss: 0.0000e+00 - total_loss: 0.2604\n",
      "Epoch 18/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.8713 - loss: 0.2370 - regularization_loss: 0.0000e+00 - total_loss: 0.2370\n",
      "Epoch 19/500\n",
      "94/94 [==============================] - 4s 46ms/step - binary_accuracy: 0.8805 - loss: 0.2171 - regularization_loss: 0.0000e+00 - total_loss: 0.2171\n",
      "Epoch 20/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.8886 - loss: 0.2004 - regularization_loss: 0.0000e+00 - total_loss: 0.2004\n",
      "Epoch 21/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.8942 - loss: 0.1891 - regularization_loss: 0.0000e+00 - total_loss: 0.1891\n",
      "Epoch 22/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.8994 - loss: 0.1794 - regularization_loss: 0.0000e+00 - total_loss: 0.1794\n",
      "Epoch 23/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9036 - loss: 0.1701 - regularization_loss: 0.0000e+00 - total_loss: 0.1701\n",
      "Epoch 24/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9075 - loss: 0.1622 - regularization_loss: 0.0000e+00 - total_loss: 0.1622\n",
      "Epoch 25/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9104 - loss: 0.1565 - regularization_loss: 0.0000e+00 - total_loss: 0.1565\n",
      "Epoch 26/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9124 - loss: 0.1524 - regularization_loss: 0.0000e+00 - total_loss: 0.1524\n",
      "Epoch 27/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9132 - loss: 0.1508 - regularization_loss: 0.0000e+00 - total_loss: 0.1508\n",
      "Epoch 28/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9169 - loss: 0.1467 - regularization_loss: 0.0000e+00 - total_loss: 0.1467\n",
      "Epoch 29/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9235 - loss: 0.1420 - regularization_loss: 0.0000e+00 - total_loss: 0.1420\n",
      "Epoch 30/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9308 - loss: 0.1319 - regularization_loss: 0.0000e+00 - total_loss: 0.1319\n",
      "Epoch 31/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9373 - loss: 0.1217 - regularization_loss: 0.0000e+00 - total_loss: 0.1217\n",
      "Epoch 32/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9427 - loss: 0.1134 - regularization_loss: 0.0000e+00 - total_loss: 0.1134\n",
      "Epoch 33/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9470 - loss: 0.1074 - regularization_loss: 0.0000e+00 - total_loss: 0.1074\n",
      "Epoch 34/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9504 - loss: 0.1018 - regularization_loss: 0.0000e+00 - total_loss: 0.1018\n",
      "Epoch 35/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9542 - loss: 0.0954 - regularization_loss: 0.0000e+00 - total_loss: 0.0954\n",
      "Epoch 36/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9567 - loss: 0.0906 - regularization_loss: 0.0000e+00 - total_loss: 0.0906\n",
      "Epoch 37/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9592 - loss: 0.0852 - regularization_loss: 0.0000e+00 - total_loss: 0.0852\n",
      "Epoch 38/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9610 - loss: 0.0818 - regularization_loss: 0.0000e+00 - total_loss: 0.0818\n",
      "Epoch 39/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9620 - loss: 0.0795 - regularization_loss: 0.0000e+00 - total_loss: 0.0795\n",
      "Epoch 40/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9630 - loss: 0.0771 - regularization_loss: 0.0000e+00 - total_loss: 0.0771\n",
      "Epoch 41/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9640 - loss: 0.0746 - regularization_loss: 0.0000e+00 - total_loss: 0.0746\n",
      "Epoch 42/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9652 - loss: 0.0726 - regularization_loss: 0.0000e+00 - total_loss: 0.0726\n",
      "Epoch 43/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9659 - loss: 0.0709 - regularization_loss: 0.0000e+00 - total_loss: 0.0709\n",
      "Epoch 44/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9669 - loss: 0.0687 - regularization_loss: 0.0000e+00 - total_loss: 0.0687\n",
      "Epoch 45/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9677 - loss: 0.0667 - regularization_loss: 0.0000e+00 - total_loss: 0.0667\n",
      "Epoch 46/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9686 - loss: 0.0650 - regularization_loss: 0.0000e+00 - total_loss: 0.0650\n",
      "Epoch 47/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9691 - loss: 0.0635 - regularization_loss: 0.0000e+00 - total_loss: 0.0635\n",
      "Epoch 48/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9700 - loss: 0.0611 - regularization_loss: 0.0000e+00 - total_loss: 0.0611\n",
      "Epoch 49/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9703 - loss: 0.0598 - regularization_loss: 0.0000e+00 - total_loss: 0.0598\n",
      "Epoch 50/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9702 - loss: 0.0596 - regularization_loss: 0.0000e+00 - total_loss: 0.0596\n",
      "Epoch 51/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9706 - loss: 0.0589 - regularization_loss: 0.0000e+00 - total_loss: 0.0589\n",
      "Epoch 52/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9712 - loss: 0.0577 - regularization_loss: 0.0000e+00 - total_loss: 0.0577\n",
      "Epoch 53/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9714 - loss: 0.0565 - regularization_loss: 0.0000e+00 - total_loss: 0.0565\n",
      "Epoch 54/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9716 - loss: 0.0561 - regularization_loss: 0.0000e+00 - total_loss: 0.0561\n",
      "Epoch 55/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9719 - loss: 0.0551 - regularization_loss: 0.0000e+00 - total_loss: 0.0551\n",
      "Epoch 56/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9723 - loss: 0.0546 - regularization_loss: 0.0000e+00 - total_loss: 0.0546\n",
      "Epoch 57/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9721 - loss: 0.0537 - regularization_loss: 0.0000e+00 - total_loss: 0.0537\n",
      "Epoch 58/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9722 - loss: 0.0533 - regularization_loss: 0.0000e+00 - total_loss: 0.0533\n",
      "Epoch 59/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9723 - loss: 0.0528 - regularization_loss: 0.0000e+00 - total_loss: 0.0528\n",
      "Epoch 60/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9721 - loss: 0.0523 - regularization_loss: 0.0000e+00 - total_loss: 0.0523\n",
      "Epoch 61/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9727 - loss: 0.0507 - regularization_loss: 0.0000e+00 - total_loss: 0.0507\n",
      "Epoch 62/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9732 - loss: 0.0490 - regularization_loss: 0.0000e+00 - total_loss: 0.0490\n",
      "Epoch 63/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9736 - loss: 0.0470 - regularization_loss: 0.0000e+00 - total_loss: 0.0470\n",
      "Epoch 64/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9741 - loss: 0.0452 - regularization_loss: 0.0000e+00 - total_loss: 0.0452\n",
      "Epoch 65/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9745 - loss: 0.0442 - regularization_loss: 0.0000e+00 - total_loss: 0.0442\n",
      "Epoch 66/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9747 - loss: 0.0438 - regularization_loss: 0.0000e+00 - total_loss: 0.0438\n",
      "Epoch 67/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9748 - loss: 0.0429 - regularization_loss: 0.0000e+00 - total_loss: 0.0429\n",
      "Epoch 68/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9750 - loss: 0.0423 - regularization_loss: 0.0000e+00 - total_loss: 0.0423\n",
      "Epoch 69/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9750 - loss: 0.0417 - regularization_loss: 0.0000e+00 - total_loss: 0.0417\n",
      "Epoch 70/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9750 - loss: 0.0410 - regularization_loss: 0.0000e+00 - total_loss: 0.0410\n",
      "Epoch 71/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9751 - loss: 0.0402 - regularization_loss: 0.0000e+00 - total_loss: 0.0402\n",
      "Epoch 72/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9752 - loss: 0.0397 - regularization_loss: 0.0000e+00 - total_loss: 0.0397\n",
      "Epoch 73/500\n",
      "94/94 [==============================] - 4s 46ms/step - binary_accuracy: 0.9755 - loss: 0.0394 - regularization_loss: 0.0000e+00 - total_loss: 0.0394\n",
      "Epoch 74/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9758 - loss: 0.0388 - regularization_loss: 0.0000e+00 - total_loss: 0.0388\n",
      "Epoch 75/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9759 - loss: 0.0387 - regularization_loss: 0.0000e+00 - total_loss: 0.0387\n",
      "Epoch 76/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9760 - loss: 0.0387 - regularization_loss: 0.0000e+00 - total_loss: 0.0387\n",
      "Epoch 77/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9760 - loss: 0.0396 - regularization_loss: 0.0000e+00 - total_loss: 0.0396\n",
      "Epoch 78/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9761 - loss: 0.0397 - regularization_loss: 0.0000e+00 - total_loss: 0.0397\n",
      "Epoch 79/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9763 - loss: 0.0399 - regularization_loss: 0.0000e+00 - total_loss: 0.0399\n",
      "Epoch 80/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9762 - loss: 0.0404 - regularization_loss: 0.0000e+00 - total_loss: 0.0404\n",
      "Epoch 81/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9762 - loss: 0.0410 - regularization_loss: 0.0000e+00 - total_loss: 0.0410\n",
      "Epoch 82/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9761 - loss: 0.0418 - regularization_loss: 0.0000e+00 - total_loss: 0.0418\n",
      "Epoch 83/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9761 - loss: 0.0419 - regularization_loss: 0.0000e+00 - total_loss: 0.0419\n",
      "Epoch 84/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9761 - loss: 0.0416 - regularization_loss: 0.0000e+00 - total_loss: 0.0416\n",
      "Epoch 85/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9765 - loss: 0.0413 - regularization_loss: 0.0000e+00 - total_loss: 0.0413\n",
      "Epoch 86/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9764 - loss: 0.0413 - regularization_loss: 0.0000e+00 - total_loss: 0.0413\n",
      "Epoch 87/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9767 - loss: 0.0403 - regularization_loss: 0.0000e+00 - total_loss: 0.0403\n",
      "Epoch 88/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9769 - loss: 0.0402 - regularization_loss: 0.0000e+00 - total_loss: 0.0402\n",
      "Epoch 89/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9772 - loss: 0.0395 - regularization_loss: 0.0000e+00 - total_loss: 0.0395\n",
      "Epoch 90/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9773 - loss: 0.0391 - regularization_loss: 0.0000e+00 - total_loss: 0.0391\n",
      "Epoch 91/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9775 - loss: 0.0390 - regularization_loss: 0.0000e+00 - total_loss: 0.0390\n",
      "Epoch 92/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9775 - loss: 0.0389 - regularization_loss: 0.0000e+00 - total_loss: 0.0389\n",
      "Epoch 93/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9777 - loss: 0.0387 - regularization_loss: 0.0000e+00 - total_loss: 0.0387\n",
      "Epoch 94/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9777 - loss: 0.0389 - regularization_loss: 0.0000e+00 - total_loss: 0.0389\n",
      "Epoch 95/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9777 - loss: 0.0390 - regularization_loss: 0.0000e+00 - total_loss: 0.0390\n",
      "Epoch 96/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9775 - loss: 0.0397 - regularization_loss: 0.0000e+00 - total_loss: 0.0397\n",
      "Epoch 97/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9775 - loss: 0.0394 - regularization_loss: 0.0000e+00 - total_loss: 0.0394\n",
      "Epoch 98/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9775 - loss: 0.0392 - regularization_loss: 0.0000e+00 - total_loss: 0.0392\n",
      "Epoch 99/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9777 - loss: 0.0389 - regularization_loss: 0.0000e+00 - total_loss: 0.0389\n",
      "Epoch 100/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9779 - loss: 0.0383 - regularization_loss: 0.0000e+00 - total_loss: 0.0383\n",
      "Epoch 101/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9779 - loss: 0.0385 - regularization_loss: 0.0000e+00 - total_loss: 0.0385\n",
      "Epoch 102/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9779 - loss: 0.0385 - regularization_loss: 0.0000e+00 - total_loss: 0.0385\n",
      "Epoch 103/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9779 - loss: 0.0383 - regularization_loss: 0.0000e+00 - total_loss: 0.0383\n",
      "Epoch 104/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9778 - loss: 0.0386 - regularization_loss: 0.0000e+00 - total_loss: 0.0386\n",
      "Epoch 105/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9776 - loss: 0.0393 - regularization_loss: 0.0000e+00 - total_loss: 0.0393\n",
      "Epoch 106/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9778 - loss: 0.0386 - regularization_loss: 0.0000e+00 - total_loss: 0.0386\n",
      "Epoch 107/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9778 - loss: 0.0382 - regularization_loss: 0.0000e+00 - total_loss: 0.0382\n",
      "Epoch 108/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9777 - loss: 0.0386 - regularization_loss: 0.0000e+00 - total_loss: 0.0386\n",
      "Epoch 109/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9779 - loss: 0.0379 - regularization_loss: 0.0000e+00 - total_loss: 0.0379\n",
      "Epoch 110/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9780 - loss: 0.0374 - regularization_loss: 0.0000e+00 - total_loss: 0.0374\n",
      "Epoch 111/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9781 - loss: 0.0378 - regularization_loss: 0.0000e+00 - total_loss: 0.0378\n",
      "Epoch 112/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9782 - loss: 0.0370 - regularization_loss: 0.0000e+00 - total_loss: 0.0370\n",
      "Epoch 113/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9783 - loss: 0.0369 - regularization_loss: 0.0000e+00 - total_loss: 0.0369\n",
      "Epoch 114/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9783 - loss: 0.0368 - regularization_loss: 0.0000e+00 - total_loss: 0.0368\n",
      "Epoch 115/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9783 - loss: 0.0365 - regularization_loss: 0.0000e+00 - total_loss: 0.0365\n",
      "Epoch 116/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9783 - loss: 0.0366 - regularization_loss: 0.0000e+00 - total_loss: 0.0366\n",
      "Epoch 117/500\n",
      "94/94 [==============================] - 4s 42ms/step - binary_accuracy: 0.9783 - loss: 0.0367 - regularization_loss: 0.0000e+00 - total_loss: 0.0367\n",
      "Epoch 118/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9784 - loss: 0.0365 - regularization_loss: 0.0000e+00 - total_loss: 0.0365\n",
      "Epoch 119/500\n",
      "94/94 [==============================] - 4s 42ms/step - binary_accuracy: 0.9783 - loss: 0.0358 - regularization_loss: 0.0000e+00 - total_loss: 0.0358\n",
      "Epoch 120/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9783 - loss: 0.0358 - regularization_loss: 0.0000e+00 - total_loss: 0.0358\n",
      "Epoch 121/500\n",
      "94/94 [==============================] - 4s 42ms/step - binary_accuracy: 0.9784 - loss: 0.0357 - regularization_loss: 0.0000e+00 - total_loss: 0.0357\n",
      "Epoch 122/500\n",
      "94/94 [==============================] - 4s 42ms/step - binary_accuracy: 0.9784 - loss: 0.0359 - regularization_loss: 0.0000e+00 - total_loss: 0.0359\n",
      "Epoch 123/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9784 - loss: 0.0358 - regularization_loss: 0.0000e+00 - total_loss: 0.0358\n",
      "Epoch 124/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9783 - loss: 0.0361 - regularization_loss: 0.0000e+00 - total_loss: 0.0361\n",
      "Epoch 125/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9781 - loss: 0.0358 - regularization_loss: 0.0000e+00 - total_loss: 0.0358\n",
      "Epoch 126/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9781 - loss: 0.0358 - regularization_loss: 0.0000e+00 - total_loss: 0.0358\n",
      "Epoch 127/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9781 - loss: 0.0361 - regularization_loss: 0.0000e+00 - total_loss: 0.0361\n",
      "Epoch 128/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9781 - loss: 0.0356 - regularization_loss: 0.0000e+00 - total_loss: 0.0356\n",
      "Epoch 129/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9782 - loss: 0.0360 - regularization_loss: 0.0000e+00 - total_loss: 0.0360\n",
      "Epoch 130/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9783 - loss: 0.0357 - regularization_loss: 0.0000e+00 - total_loss: 0.0357\n",
      "Epoch 131/500\n",
      "94/94 [==============================] - 4s 43ms/step - binary_accuracy: 0.9783 - loss: 0.0358 - regularization_loss: 0.0000e+00 - total_loss: 0.0358\n",
      "Epoch 132/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9783 - loss: 0.0357 - regularization_loss: 0.0000e+00 - total_loss: 0.0357\n",
      "Epoch 133/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9783 - loss: 0.0352 - regularization_loss: 0.0000e+00 - total_loss: 0.0352\n",
      "Epoch 134/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9786 - loss: 0.0345 - regularization_loss: 0.0000e+00 - total_loss: 0.0345\n",
      "Epoch 135/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9786 - loss: 0.0342 - regularization_loss: 0.0000e+00 - total_loss: 0.0342\n",
      "Epoch 136/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9786 - loss: 0.0343 - regularization_loss: 0.0000e+00 - total_loss: 0.0343\n",
      "Epoch 137/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9784 - loss: 0.0345 - regularization_loss: 0.0000e+00 - total_loss: 0.0345\n",
      "Epoch 138/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9786 - loss: 0.0345 - regularization_loss: 0.0000e+00 - total_loss: 0.0345\n",
      "Epoch 139/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9785 - loss: 0.0345 - regularization_loss: 0.0000e+00 - total_loss: 0.0345\n",
      "Epoch 140/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9786 - loss: 0.0344 - regularization_loss: 0.0000e+00 - total_loss: 0.0344\n",
      "Epoch 141/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9786 - loss: 0.0343 - regularization_loss: 0.0000e+00 - total_loss: 0.0343\n",
      "Epoch 142/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9785 - loss: 0.0345 - regularization_loss: 0.0000e+00 - total_loss: 0.0345\n",
      "Epoch 143/500\n",
      "94/94 [==============================] - 4s 46ms/step - binary_accuracy: 0.9785 - loss: 0.0349 - regularization_loss: 0.0000e+00 - total_loss: 0.0349\n",
      "Epoch 144/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9785 - loss: 0.0347 - regularization_loss: 0.0000e+00 - total_loss: 0.0347\n",
      "Epoch 145/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9786 - loss: 0.0346 - regularization_loss: 0.0000e+00 - total_loss: 0.0346\n",
      "Epoch 146/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9786 - loss: 0.0341 - regularization_loss: 0.0000e+00 - total_loss: 0.0341\n",
      "Epoch 147/500\n",
      "94/94 [==============================] - 4s 45ms/step - binary_accuracy: 0.9786 - loss: 0.0345 - regularization_loss: 0.0000e+00 - total_loss: 0.0345\n",
      "Epoch 148/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9785 - loss: 0.0344 - regularization_loss: 0.0000e+00 - total_loss: 0.0344\n",
      "Epoch 149/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9784 - loss: 0.0346 - regularization_loss: 0.0000e+00 - total_loss: 0.0346\n",
      "Epoch 150/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9784 - loss: 0.0348 - regularization_loss: 0.0000e+00 - total_loss: 0.0348\n",
      "Epoch 151/500\n",
      "94/94 [==============================] - 4s 44ms/step - binary_accuracy: 0.9786 - loss: 0.0348 - regularization_loss: 0.0000e+00 - total_loss: 0.0348\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(cached_train,\n",
    "                     epochs = 500,\n",
    "                     callbacks = callbacks_list,\n",
    "                     verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f10TwemRD14",
    "outputId": "dd30bb72-e654-419e-ce9d-384c113f901d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC: 0.9520474448469282\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91     88227\n",
      "           1       0.92      0.93      0.92    100491\n",
      "\n",
      "    accuracy                           0.92    188718\n",
      "   macro avg       0.92      0.92      0.92    188718\n",
      "weighted avg       0.92      0.92      0.92    188718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_result(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPjKUFedR27j",
    "outputId": "f12cd83f-9de8-452f-a972-54fd2245f645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dcn_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_103 (Sequential)  (None, 32)                2112      \n",
      "_________________________________________________________________\n",
      "sequential_104 (Sequential)  (None, 32)                896       \n",
      "_________________________________________________________________\n",
      "sequential_102 (Sequential)  (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "sequential_96 (Sequential)   (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "sequential_95 (Sequential)   (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "sequential_100 (Sequential)  (None, 32)                864       \n",
      "_________________________________________________________________\n",
      "sequential_99 (Sequential)   (None, 32)                254688    \n",
      "_________________________________________________________________\n",
      "sequential_97 (Sequential)   (None, 32)                61152     \n",
      "_________________________________________________________________\n",
      "sequential_101 (Sequential)  (None, 32)                33152     \n",
      "_________________________________________________________________\n",
      "sequential_98 (Sequential)   (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "sequential_94 (Sequential)   (None, 32)                256       \n",
      "_________________________________________________________________\n",
      "sequential_92 (Sequential)   (None, 32)                203008    \n",
      "_________________________________________________________________\n",
      "sequential_93 (Sequential)   (None, 32)                1627264   \n",
      "_________________________________________________________________\n",
      "cross_7 (Cross)              multiple                  173472    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             multiple                  80064     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             multiple                  37056     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             multiple                  193       \n",
      "_________________________________________________________________\n",
      "ranking_7 (Ranking)          multiple                  2         \n",
      "=================================================================\n",
      "Total params: 2,476,515\n",
      "Trainable params: 2,476,513\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "id": "Bc-ek27ySuOp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1227_DCN_practive.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
