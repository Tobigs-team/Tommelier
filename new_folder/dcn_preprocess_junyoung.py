# -*- coding: utf-8 -*-
"""DCN_preprocess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/158xtrPNdk4vWWhf2-kv9YAliYkhNdi1d

# DCN-preprocess
"""

import os
import pandas as pd
import tensorflow as tf
import numpy as np
import tensorflow_recommenders as tfrs
from tqdm import tqdm



def DCN_preprocessing(df, str_features, int_features, df_type = 'train'):
    feature_names = str_features + int_features

    def setType(df):
        df = df.reset_index(drop=True)
        df.country_code= df.country_code.fillna('un')
        df['grapes_id'] = df.grapes_id.map(lambda x: x[0] if x else 0)
        df=df[~df.type_id.isna()]
        df=df.drop(df[df['type_id']==25].index)
        df = df[~df.body.isna()].reset_index(drop=True)
        for int_feature in int_features:
            df[int_feature] = df[int_feature].astype(int)
        return df

    def generateDict(df):
        train_str_dict = {
            str_feature: [str(val).encode() for val in df[str_feature].values]
            for str_feature in str_features
        }

        train_int_dict = {
            int_feature: df[int_feature].values
            for int_feature in int_features
        }
        
        # label columns이 있다면~
        try:
            train_label_dict = {
                'like' : df['like'].values
            }
            train_str_dict.update(train_label_dict)
        except:
            pass
        try:
            train_label_dict = {
                'rating_per_user' : df['rating_per_user'].values
            }
            train_str_dict.update(train_label_dict)
        except:
            pass
        
        
        train_str_dict.update(train_int_dict)                
        return train_str_dict

    df_copy = setType(df)
    input_dict = generateDict(df_copy)
    
    # tensor
    tensor = tf.data.Dataset.from_tensor_slices(input_dict)
    cached = tensor.shuffle(100_000).batch(8192).cache()
    if df_type == 'train':
        vocabularies = {}

        for feature_name in feature_names:
            vocab = tensor.batch(1_000_000).map(lambda x: x[feature_name])
            vocabularies[feature_name] = np.unique(np.concatenate(list(vocab)))
        
        return cached, vocabularies
    
    else:
        return cached